# 1 Flink全景速览

## 1.1 流与批的统一视角

### 1.1.1 两种计算范式的历史包袱

大数据处理的发展，其实就是一部不断追求“快”与“准”的历史。

最早，大家依赖批处理系统。那时候 Hadoop 横空出世，能够存储和处理前所未有的大规模数据，带来了一场技术革命。但它的缺点也很明显：计算延迟太高，往往要等到几个小时甚至一天之后，才能拿到结果。对于需要实时响应的业务来说，这显然不够。

于是，流处理框架出现了。它能在数据到达的瞬间就触发计算，让实时分析成为可能。但流处理的难题在于，结果通常只是近似的，很难保证像批处理那样的全局一致性。

在“快”和“准”的拉扯下，**Lambda 架构**诞生了。它把数据分成两条路走：一条进入批处理，保证最终的精确；一条进入流处理，保证实时的反馈。这个设计在当时很聪明，既满足了实时性，又兼顾了准确性。然而，使用过的人很快发现，它带来的开发和运维负担极其沉重——同一份业务逻辑要写两遍，批的写一遍，流的再写一遍，系统复杂度随着数据规模和业务增长成倍上升。

为了简化这种复杂性，**Kappa 架构**被提出。它大胆地去掉了批处理层，只保留一条流处理管道。如果需要批处理，只要把历史数据流重放一遍即可。这个思路确实让系统架构轻了不少，但它并没有真正消除“批”的需求，而是把批变成了流的一种特殊实现。结果是：虽然比 Lambda 简单，但在表达力和灵活性上仍然存在限制。

直到 **Flink** 的出现，才算为这一长期的困境画上了句号。Flink 提出了一个全新的视角：**批并不是流的对立面，而是一种“有界流”**。基于这一理念，Flink 用同一套引擎和 API 同时支持流与批，实现了真正意义上的“流批一体”。这意味着开发者不必再在两种架构之间摇摆，也不必为同一逻辑维护两套代码。Flink 把复杂性藏在了引擎之下，让用户获得了统一而简洁的编程体验。

### 1.1.2 Table API & SQL 的统一语义

在大数据处理的世界里，SQL 一直是最通用、最被接受的接口。无论是数据分析师还是工程师，SQL 都是他们沟通数据的共同语言。然而，在传统架构下，SQL 却常常面临割裂：**同样一条 SQL**，如果跑在批处理系统上，它意味着一次性计算出完整的结果；而如果跑在流处理系统上，它则需要不断更新、持续输出。对用户来说，这种割裂意味着学习和使用成本的增加——同样的业务需求，往往要用不同的语义去描述。

Flink 的突破点，就在于它提出了 **统一的 Table API & SQL 语义**。核心理念是：所有表，本质上都是 **动态表（Dynamic Table）**。所谓动态表，就是一个随时间不断变化的数据视图。批处理中的表，其实只是一个在某个时刻被“截取下来的”有限快照；而流处理中的表，则是一个无限延展、持续更新的动态过程。这样一来，**批和流不再是两套语义，而是同一概念在不同场景下的表现**。

更进一步，用户不需要关心执行模式的选择。Flink 的查询优化器会自动识别数据源的性质：

- 如果是**有限的数据源**（比如一份静态文件），系统会采用批处理模式（Block-style shuffle），一次性算完、落盘；
- 如果是**无限的数据源**（比如一个 Kafka 流），系统则会采用流处理模式（Pipeline-style exchange），让结果持续更新。

对于开发者而言，这意味着：写下的 SQL 是同一条，至于它究竟以“流”的方式不断产出结果，还是以“批”的方式一次性完成计算，完全由引擎自动决定。

举个例子，假设用户写了一条统计订单总金额的 SQL。如果跑在流模式下，它会随着每一笔新订单的到来，不断刷新累计结果；如果跑在批模式下，它会在数据全部处理完后，产出一个完整的最终结果。**逻辑相同，语义统一，执行模式交给引擎去选择**。

这种设计背后的价值不只是在“少写几行代码”，而是让数据开发者彻底摆脱了批与流之间的分裂。从此，SQL 真正成为了无缝贯通两种计算模式的统一语言。

### 1.1.3 DataStream API 统一模型

如果说 Table API & SQL 的统一语义让上层开发者能够“一条 SQL 走天下”，那么在更底层的编程接口上，Flink 也做了同样的事情——这就是 **DataStream API 的统一模型**。

在早期的流批系统里，开发者往往需要面对两种完全不同的 API：一套针对流数据（无限数据），另一套针对批数据（有限数据）。这不仅增加了学习成本，也让代码难以在不同场景下复用。Flink 的思路则更为彻底：**无论是无限数据流，还是有限数据集，都抽象成 DataStream**。区别只在于：前者是一个 **无限 DataStream**，后者是一个 **有界DataStream**。

在实际使用时，用户仅需一行代码即可完成运行模式的切换，但在运行中，Flink 会根据任务的性质自动调整底层执行策略：

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

env.setRuntimeMode(RuntimeExecutionMode.BATCH);   // 有界 → 批
// env.setRuntimeMode(RuntimeExecutionMode.STREAMING); // 无界 → 流
```



- **Task 调度**：批处理任务通常能够预先规划完整的执行 DAG，而流处理任务则需要以持续运行的算子链来驱动。
- **Checkpoint 机制**：流任务需要定期保存状态以实现故障恢复，而批任务则可以依靠数据有界性的天然确定性，大幅减少状态管理的负担。
- **Watermark 策略**：在无限流中，Watermark 是必不可少的，用来处理乱序事件和时间窗口；而在有限流中，系统可以直接推断出数据的结束点，从而简化时间语义的处理。

这种差异都被隐藏在引擎内部，对开发者透明。你写的代码不用因为数据是“流”还是“批”而改变。

例如，一个最经典的 **WordCount 程序**：

- 在**流模式**下，它会不断消费输入数据流，实时更新每个单词的计数。
- 在**批模式**下，它会在数据全部到达后，计算出最终的完整结果。

两种模式下的源和执行方式不同，但用户编写的 DataStream 程序几乎保持一致。

这正是 Flink 的统一模型魅力所在：**开发者写一份逻辑，系统自动决定是以流的方式持续运行，还是以批的方式一次性完成**。对用户来说，复杂性被彻底屏蔽，留下的只是清晰而一致的编程体验。

### 1.1.4 运行时差异深度拆解

 • Task 调度：批模式 Eager 部署、流模式懒加载
 • Shuffle：Hash vs Pipeline 的网络栈差异
 • Checkpoint：批模式自动关闭 barrier，流模式启用对齐
 • 资源释放：批任务完成后 TM 立即回收，流任务常驻

### 1.1.5 开发决策树

 • 什么时候手动指定 `setRuntimeMode(BATCH)`
 • 什么时候让 Planner 自动选择
 • 混合场景：Iceberg 全量离线回填 + 增量实时消费

### 1.1.6 小结与思维导图

 • 一张图总结「流 = 无限 + 持续结果，批 = 有限 + 单次结果」
 • 一句话记忆：Bounded 决定调度，API 保持不变。



## 1.2 运行时组件：JM / TM / Dispatcher / ResourceManager



## 1.3 逻辑视图 vs 物理执行图



## 1.4 与 Spark / Kafka Streams 的架构差异

